


application {
  field.delimiter=","
  file.Rollover.interval=60
  hdfs.output.path="file:///D://temp/flink-Kafka2Hdfs-data/"
  hdfs.path.date.format="yyyyMMdd"
}
//mysql {
//  jdbc.driver="com.mysql.jdbc.Driver"
//  url="jdbc:mysql://10.19.1.29:3306/temp?useUnicode=true&characte&useSSL=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false"
//  username="zxber"
//  password="8in3PtpeO1dRvxzd7vzTqlSxxxzOr1AG"
//}
mysql {
  jdbc.driver="com.mysql.jdbc.Driver"
  url="jdbc:mysql://10.19.5.30:3310/ms_order?useUnicode=true&characte&useSSL=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false"
  username="bi_sqoop"
  password="LOEKfDiHuVFK"
}

flink {
  checkpoint.uri="/temp/flink-ckdir/"
  checkpoint.interval=60000
  fs.default.scheme="hdfs://ip:8020"
}
kafka {
  bootstrap.servers = "kafka1:9092,kafka2:9092,kafka3:9092"
  source.topics = "test"
  group.id = "gz_test_01"
  auto.offset.reset = "latest"
//  auto.offset.reset = "earliest"
  enable.auto.commit = "true"
  auto.commit.interval.ms = 5000
  max.request.size = 2097152
}
